{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import csv\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# for named entity\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk, tree\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# nltk for natural language processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r'./playstorereviewsdata/' # use your path\n",
    "allFiles = glob.glob(path + \"/*.tsv\")\n",
    "\n",
    "# for out_count, file in enumerate(allFiles):\n",
    "#     with open(file, newline='') as csvfile:\n",
    "#         spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "#         #import pdb;pdb.set_trace()\n",
    "#         for counter, row in enumerate(spamreader):\n",
    "#             import pdb;pdb.set_trace()\n",
    "#             print(row)\n",
    "            \n",
    "#     with open(file+out_count, 'wt') as csvfile:\n",
    "#             writer = csv.writer(csvfile, delimiter='', quotechar='|')\n",
    "#             #writer.writerow([\"#\"] + anarkali_characteristics)\n",
    "#             #import pdb;pdb.set_trace()\n",
    "#             for element in lehenga_characteristics:\n",
    "#                 #import pdb;pdb.set_trace()\n",
    "#                 writer.writerow([element[\"name\"], element[\"count\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App Version Code</th>\n",
       "      <th>App Version Name</th>\n",
       "      <th>Developer Reply Date and Time</th>\n",
       "      <th>Developer Reply Millis Since Epoch</th>\n",
       "      <th>Developer Reply Text</th>\n",
       "      <th>Device</th>\n",
       "      <th>Package Name</th>\n",
       "      <th>Review Last Update Date and Time</th>\n",
       "      <th>Review Last Update Millis Since Epoch</th>\n",
       "      <th>Review Link</th>\n",
       "      <th>Review Submit Date and Time</th>\n",
       "      <th>Review Submit Millis Since Epoch</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Reviewer Language</th>\n",
       "      <th>Star Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m7</td>\n",
       "      <td>com.flyrobe.android</td>\n",
       "      <td>2015-08-09T07:05:36Z</td>\n",
       "      <td>1439103936468</td>\n",
       "      <td>https://play.google.com/apps/publish?dev_acc=0...</td>\n",
       "      <td>2015-08-09T07:05:36Z</td>\n",
       "      <td>1439103936468</td>\n",
       "      <td>This is a brilliant concept. Please start for ...</td>\n",
       "      <td>Great product!</td>\n",
       "      <td>en</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>falcon_umtsds</td>\n",
       "      <td>com.flyrobe.android</td>\n",
       "      <td>2015-08-09T10:05:06Z</td>\n",
       "      <td>1439114706593</td>\n",
       "      <td>https://play.google.com/apps/publish?dev_acc=0...</td>\n",
       "      <td>2015-08-09T10:05:06Z</td>\n",
       "      <td>1439114706593</td>\n",
       "      <td>Brilliant concept :)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>k3g</td>\n",
       "      <td>com.flyrobe.android</td>\n",
       "      <td>2015-08-09T11:51:54Z</td>\n",
       "      <td>1439121114161</td>\n",
       "      <td>https://play.google.com/apps/publish?dev_acc=0...</td>\n",
       "      <td>2015-08-09T11:51:54Z</td>\n",
       "      <td>1439121114160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>htc_m8</td>\n",
       "      <td>com.flyrobe.android</td>\n",
       "      <td>2015-08-09T12:03:11Z</td>\n",
       "      <td>1439121791786</td>\n",
       "      <td>https://play.google.com/apps/publish?dev_acc=0...</td>\n",
       "      <td>2015-08-09T12:03:11Z</td>\n",
       "      <td>1439121791786</td>\n",
       "      <td>Brilliant stuff!! Waiting to see more..</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>titan_umtsds</td>\n",
       "      <td>com.flyrobe.android</td>\n",
       "      <td>2015-08-09T12:12:04Z</td>\n",
       "      <td>1439122324704</td>\n",
       "      <td>https://play.google.com/apps/publish?dev_acc=0...</td>\n",
       "      <td>2015-08-09T12:12:04Z</td>\n",
       "      <td>1439122324704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   App Version Code App Version Name Developer Reply Date and Time  \\\n",
       "0               1.0              NaN                           NaN   \n",
       "1               NaN              NaN                           NaN   \n",
       "2               NaN              NaN                           NaN   \n",
       "3               1.0              NaN                           NaN   \n",
       "4               1.0              NaN                           NaN   \n",
       "\n",
       "   Developer Reply Millis Since Epoch Developer Reply Text         Device  \\\n",
       "0                                 NaN                  NaN             m7   \n",
       "1                                 NaN                  NaN  falcon_umtsds   \n",
       "2                                 NaN                  NaN            k3g   \n",
       "3                                 NaN                  NaN         htc_m8   \n",
       "4                                 NaN                  NaN   titan_umtsds   \n",
       "\n",
       "          Package Name Review Last Update Date and Time  \\\n",
       "0  com.flyrobe.android             2015-08-09T07:05:36Z   \n",
       "1  com.flyrobe.android             2015-08-09T10:05:06Z   \n",
       "2  com.flyrobe.android             2015-08-09T11:51:54Z   \n",
       "3  com.flyrobe.android             2015-08-09T12:03:11Z   \n",
       "4  com.flyrobe.android             2015-08-09T12:12:04Z   \n",
       "\n",
       "   Review Last Update Millis Since Epoch  \\\n",
       "0                          1439103936468   \n",
       "1                          1439114706593   \n",
       "2                          1439121114161   \n",
       "3                          1439121791786   \n",
       "4                          1439122324704   \n",
       "\n",
       "                                         Review Link  \\\n",
       "0  https://play.google.com/apps/publish?dev_acc=0...   \n",
       "1  https://play.google.com/apps/publish?dev_acc=0...   \n",
       "2  https://play.google.com/apps/publish?dev_acc=0...   \n",
       "3  https://play.google.com/apps/publish?dev_acc=0...   \n",
       "4  https://play.google.com/apps/publish?dev_acc=0...   \n",
       "\n",
       "  Review Submit Date and Time  Review Submit Millis Since Epoch  \\\n",
       "0        2015-08-09T07:05:36Z                     1439103936468   \n",
       "1        2015-08-09T10:05:06Z                     1439114706593   \n",
       "2        2015-08-09T11:51:54Z                     1439121114160   \n",
       "3        2015-08-09T12:03:11Z                     1439121791786   \n",
       "4        2015-08-09T12:12:04Z                     1439122324704   \n",
       "\n",
       "                                         Review Text    Review Title  \\\n",
       "0  This is a brilliant concept. Please start for ...  Great product!   \n",
       "1                               Brilliant concept :)             NaN   \n",
       "2                                                NaN             NaN   \n",
       "3            Brilliant stuff!! Waiting to see more..             NaN   \n",
       "4                                                NaN             NaN   \n",
       "\n",
       "  Reviewer Language  Star Rating  \n",
       "0                en            5  \n",
       "1                en            5  \n",
       "2                en            5  \n",
       "3                en            5  \n",
       "4                en            5  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get full data\n",
    "\n",
    "\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "\n",
    "# datacolumns = [\n",
    "#     \"Package Name\",\n",
    "#     \"App Version Code\",\n",
    "#     \"Reviewer Language\",\n",
    "#     \"Device\",\n",
    "#     \"Review Submit Date and Time\",\n",
    "#     \"Review Submit Millis Since Epoch\",\n",
    "#     \"Review Last Update Date and Time\",\n",
    "#     \"Review Last Update Millis Since Epoch\",\n",
    "#     \"Star Rating\",\n",
    "#     \"Review Title\",\n",
    "#     \"Review Text\",\n",
    "#     \"Developer Reply Date and Time\",\n",
    "#     \"Developer Reply Millis Since Epoch\",\n",
    "#     \"Developer Reply Text,Review Link\"\n",
    "# ]\n",
    "\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, encoding = \"ISO-8859-1\", error_bad_lines=False, sep='\\t')\n",
    "    list_.append(df)\n",
    "    \n",
    "    \n",
    "full_data = pd.concat(list_)\n",
    "full_data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the NaN \n",
    "full_data[\"Review Text\"] = full_data[\"Review Text\"].fillna('')\n",
    "full_data[\"Review Title\"] = full_data[\"Review Title\"].fillna('')\n",
    "full_data[\"App Version Code\"] = full_data[\"App Version Code\"].fillna(0.0)\n",
    "full_data[\"App Version Name\"] = full_data[\"App Version Name\"].fillna('')\n",
    "full_data[\"Developer Reply Date and Time\"] = full_data[\"Developer Reply Date and Time\"].fillna('')\n",
    "full_data[\"Developer Reply Millis Since Epoch\"] = full_data[\"Developer Reply Millis Since Epoch\"].fillna('')\n",
    "full_data[\"Developer Reply Text\"] = full_data[\"Developer Reply Text\"].fillna('')\n",
    "\n",
    "# slicing the required columns only\n",
    "full_data = full_data[[\"Review Text\", \"Review Title\", \"Star Rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Star Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a brilliant concept. Please start for ...</td>\n",
       "      <td>Great product!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brilliant concept :)</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brilliant stuff!! Waiting to see more..</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text    Review Title  \\\n",
       "0  This is a brilliant concept. Please start for ...  Great product!   \n",
       "1                               Brilliant concept :)                   \n",
       "2                                                                      \n",
       "3            Brilliant stuff!! Waiting to see more..                   \n",
       "4                                                                      \n",
       "\n",
       "   Star Rating  \n",
       "0            5  \n",
       "1            5  \n",
       "2            5  \n",
       "3            5  \n",
       "4            5  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data.loc[full_data['Review Text'] != '']\n",
    "full_data[\"Positive\"] = full_data['Star Rating'] >= 4\n",
    "full_data[\"Negative\"] = full_data['Star Rating'] <= 3\n",
    "\n",
    "positive_data = full_data.loc[(full_data['Negative'] == True)][:500]\n",
    "negative_data = full_data.loc[(full_data['Positive'] == True)][:500]\n",
    "\n",
    "# add a named entities to look for\n",
    "#import pdb;pdb.set_trace()\n",
    "\n",
    "sliced_data = positive_data.append(negative_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sliced_data[\"Named Entities\"] = [ne_chunk(pos_tag(word_tokenize(item))) for item in sliced_data['Review Text'].tolist()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50           What's the access code???I am stuck there!!\n",
       "52                                  Stuck in access code\n",
       "53     Quickly send or give an invite code. Email id ...\n",
       "135    I'm glad this thing is now available in India ...\n",
       "162                     how to log in??? access code????\n",
       "165    What's d use if v can now take access with out...\n",
       "176    Hiii management... how do I login inn into the...\n",
       "183                                I'm not able to login\n",
       "13     I have trouble accessing to d special dresses ...\n",
       "16         Dsnt install on my phone ð£ please help out\n",
       "17                          Keeps on throwing error 504.\n",
       "20     It's not getting installed bcz of this \" error...\n",
       "28     I can't open reserve categories.I really want ...\n",
       "35     Installed it and it simply gets stuck. Cant se...\n",
       "92                   Traditiona thing not getting opened\n",
       "4      The pictures just don't load! I have a 4g conn...\n",
       "7      I dont have fb account..is there any other opt...\n",
       "15     No images are loaded.. Everytime I click on a ...\n",
       "16     A nice concept, must try at least once, but th...\n",
       "17     After booking the dates for the outfits ..no o...\n",
       "24     As I have installed dis app n logged in throug...\n",
       "28     If i choose a date and then if i go and select...\n",
       "34     Whnevr i open any category it jst shws no item...\n",
       "64     I downloaded the app, however it keeps crashin...\n",
       "91     Shows no items...installed and uninstalled all...\n",
       "2      The app just hangs up and crashes when I click...\n",
       "38     And if we want to return in 12 hrs the service...\n",
       "43            Dont waste ur mb by downloading this app .\n",
       "47     This app needs compulsory facebook login..What...\n",
       "56                     Is this available in Delhi also ?\n",
       "                             ...                        \n",
       "119    I like the concept. Giving branded wears on a ...\n",
       "120    Collections are so good ethnic wear collection...\n",
       "121                                             Nice one\n",
       "122    Loved it. Now i dnt have to think twice for ex...\n",
       "124                              The app is awesome! â¤\n",
       "126    Amazing experience with wonderful service.. Qu...\n",
       "127    Nothing to wear? Just rent it from flyrobe. To...\n",
       "129    Rented Lehenga for my brother's engagement. My...\n",
       "130     It is very wonderful app for bying ... i love it\n",
       "131    What an amazing, much needed App for every wom...\n",
       "0                   Collections are so good and nice app\n",
       "3                                              I love it\n",
       "4                                          Excellent job\n",
       "5      It's great to have a wardrobe which covers alm...\n",
       "6      I'm facing a problem though... Even though I f...\n",
       "10                                     Fabulous ðð\n",
       "11                                               Amazing\n",
       "17     Ordered two outfits which turned out to be as ...\n",
       "19                                  Just simply loved it\n",
       "28     beautiful feedback , But only one FLYR0BE is i...\n",
       "37     Its an amazing app with an amazing concept of ...\n",
       "49     I have a query about the security deposit on e...\n",
       "55     Awesome collection plus awesome service..premi...\n",
       "58     Loved the idea of having my own wardrobe -with...\n",
       "59                                  Loved the collection\n",
       "60               Awesome collection and customer service\n",
       "63     You people are doing some incredible job. Righ...\n",
       "66     The clothes may it be western or ethnic all ar...\n",
       "68     Best customer care service ever experienced......\n",
       "69     Very very good feedback from the customer care...\n",
       "Name: Review Text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df = sliced_data[['Review Text', 'Star Rating']]\n",
    "sliced_data['Review Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "> <ipython-input-27-d3c877227db0>(94)<module>()->None\n",
      "-> import pdb;pdb.set_trace()\n",
      "(Pdb) final_sliced_data[['ops_prob', 'tech_prob', 'product_prob']].max(axis=1)\n",
      "50     0.000000\n",
      "52     0.000000\n",
      "53     0.000000\n",
      "135    1.000000\n",
      "162    0.000000\n",
      "165    0.000000\n",
      "176    0.000000\n",
      "183    0.000000\n",
      "13     0.000000\n",
      "16     0.000000\n",
      "17     1.000000\n",
      "20     1.000000\n",
      "28     0.000000\n",
      "35     0.000000\n",
      "92     0.000000\n",
      "4      0.000000\n",
      "7      0.000000\n",
      "15     1.000000\n",
      "16     1.000000\n",
      "17     1.000000\n",
      "24     0.000000\n",
      "28     1.000000\n",
      "34     1.000000\n",
      "64     0.000000\n",
      "91     1.000000\n",
      "2      1.000000\n",
      "38     1.000000\n",
      "43     1.000000\n",
      "47     0.000000\n",
      "56     1.000000\n",
      "         ...   \n",
      "119    0.000000\n",
      "120    0.000000\n",
      "121    0.000000\n",
      "122    0.000000\n",
      "124    0.000000\n",
      "126    0.000000\n",
      "127    1.000000\n",
      "129    0.000000\n",
      "130    0.000000\n",
      "131    0.000000\n",
      "0      0.000000\n",
      "3      0.000000\n",
      "4      0.000000\n",
      "5      0.000000\n",
      "6      0.000000\n",
      "10     0.000000\n",
      "11     0.000000\n",
      "17     0.714286\n",
      "19     0.000000\n",
      "28     0.000000\n",
      "37     0.000000\n",
      "49     1.000000\n",
      "55     0.000000\n",
      "58     0.000000\n",
      "59     0.000000\n",
      "60     0.000000\n",
      "63     0.666667\n",
      "66     0.000000\n",
      "68     0.000000\n",
      "69     0.000000\n",
      "Length: 1000, dtype: float64\n",
      "(Pdb) dir(final_sliced_data[['ops_prob', 'tech_prob', 'product_prob']].max(axis=1))\n",
      "['T', '_AXIS_ALIASES', '_AXIS_IALIASES', '_AXIS_LEN', '_AXIS_NAMES', '_AXIS_NUMBERS', '_AXIS_ORDERS', '_AXIS_REVERSED', '_AXIS_SLICEMAP', '__abs__', '__add__', '__and__', '__array__', '__array_prepare__', '__array_priority__', '__array_wrap__', '__bool__', '__bytes__', '__class__', '__contains__', '__copy__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__div__', '__divmod__', '__doc__', '__eq__', '__finalize__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__iadd__', '__iand__', '__ifloordiv__', '__imod__', '__imul__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__long__', '__lt__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pow__', '__radd__', '__rand__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__unicode__', '__weakref__', '__xor__', '_accessors', '_add_numeric_operations', '_add_series_only_operations', '_add_series_or_dataframe_operations', '_agg_by_level', '_agg_doc', '_aggregate', '_aggregate_multiple_funcs', '_align_frame', '_align_series', '_allow_index_ops', '_at', '_binop', '_box_item_values', '_builtin_table', '_can_hold_na', '_check_inplace_setting', '_check_is_chained_assignment_possible', '_check_percentile', '_check_setitem_copy', '_clear_item_cache', '_clip_with_one_bound', '_clip_with_scalar', '_consolidate', '_consolidate_inplace', '_construct_axes_dict', '_construct_axes_dict_for_slice', '_construct_axes_dict_from', '_construct_axes_from_arguments', '_constructor', '_constructor_expanddim', '_constructor_sliced', '_convert', '_create_indexer', '_cython_table', '_deprecations', '_dir_additions', '_dir_deletions', '_drop_axis', '_expand_axes', '_formatting_values', '_from_axes', '_get_axis', '_get_axis_name', '_get_axis_number', '_get_axis_resolvers', '_get_block_manager_axis', '_get_bool_data', '_get_cacher', '_get_index_resolvers', '_get_item_cache', '_get_numeric_data', '_get_value', '_get_values', '_get_values_tuple', '_get_with', '_gotitem', '_iat', '_iget_item_cache', '_iloc', '_index', '_indexed_same', '_info_axis', '_info_axis_name', '_info_axis_number', '_init_mgr', '_internal_names', '_internal_names_set', '_is_builtin_func', '_is_cached', '_is_cython_func', '_is_datelike_mixed_type', '_is_mixed_type', '_is_numeric_mixed_type', '_is_view', '_ix', '_ixs', '_loc', '_maybe_cache_changed', '_maybe_update_cacher', '_metadata', '_needs_reindex_multi', '_obj_with_exclusions', '_protect_consolidate', '_reduce', '_reindex_axes', '_reindex_axis', '_reindex_indexer', '_reindex_multi', '_reindex_with_indexers', '_repr_data_resource_', '_repr_latex_', '_reset_cache', '_reset_cacher', '_selected_obj', '_selection', '_selection_list', '_selection_name', '_set_as_cached', '_set_axis', '_set_axis_name', '_set_is_copy', '_set_item', '_set_labels', '_set_name', '_set_subtyp', '_set_value', '_set_values', '_set_with', '_set_with_engine', '_setup_axes', '_shallow_copy', '_slice', '_stat_axis', '_stat_axis_name', '_stat_axis_number', '_take', '_to_dict_of_blocks', '_try_aggregate_string_function', '_typ', '_unpickle_series_compat', '_update_inplace', '_validate_dtype', '_values', '_where', '_xs', 'abs', 'add', 'add_prefix', 'add_suffix', 'agg', 'aggregate', 'align', 'all', 'any', 'append', 'apply', 'argmax', 'argmin', 'argsort', 'as_matrix', 'asfreq', 'asobject', 'asof', 'astype', 'at', 'at_time', 'autocorr', 'axes', 'base', 'between', 'between_time', 'bfill', 'bool', 'clip', 'clip_lower', 'clip_upper', 'combine', 'combine_first', 'compound', 'compress', 'copy', 'corr', 'count', 'cov', 'cummax', 'cummin', 'cumprod', 'cumsum', 'data', 'describe', 'diff', 'div', 'divide', 'dot', 'drop', 'drop_duplicates', 'dropna', 'dtype', 'dtypes', 'duplicated', 'empty', 'eq', 'equals', 'ewm', 'expanding', 'factorize', 'ffill', 'fillna', 'filter', 'first', 'first_valid_index', 'flags', 'floordiv', 'from_array', 'ftype', 'ftypes', 'ge', 'get', 'get_dtype_counts', 'get_ftype_counts', 'get_values', 'groupby', 'gt', 'hasnans', 'head', 'hist', 'iat', 'idxmax', 'idxmin', 'iloc', 'imag', 'index', 'infer_objects', 'interpolate', 'is_copy', 'is_monotonic', 'is_monotonic_decreasing', 'is_monotonic_increasing', 'is_unique', 'isin', 'isna', 'isnull', 'item', 'items', 'itemsize', 'iteritems', 'ix', 'keys', 'kurt', 'kurtosis', 'last', 'last_valid_index', 'le', 'loc', 'lt', 'mad', 'map', 'mask', 'max', 'mean', 'median', 'memory_usage', 'min', 'mod', 'mode', 'mul', 'multiply', 'name', 'nbytes', 'ndim', 'ne', 'nlargest', 'nonzero', 'notna', 'notnull', 'nsmallest', 'nunique', 'pct_change', 'pipe', 'plot', 'pop', 'pow', 'prod', 'product', 'ptp', 'put', 'quantile', 'radd', 'rank', 'ravel', 'rdiv', 'real', 'reindex', 'reindex_axis', 'reindex_like', 'rename', 'rename_axis', 'reorder_levels', 'repeat', 'replace', 'resample', 'reset_index', 'rfloordiv', 'rmod', 'rmul', 'rolling', 'round', 'rpow', 'rsub', 'rtruediv', 'sample', 'searchsorted', 'select', 'sem', 'set_axis', 'shape', 'shift', 'size', 'skew', 'slice_shift', 'sort_index', 'sort_values', 'squeeze', 'std', 'strides', 'sub', 'subtract', 'sum', 'swapaxes', 'swaplevel', 'tail', 'take', 'to_clipboard', 'to_csv', 'to_dense', 'to_dict', 'to_excel', 'to_frame', 'to_hdf', 'to_json', 'to_latex', 'to_msgpack', 'to_period', 'to_pickle', 'to_sparse', 'to_sql', 'to_string', 'to_timestamp', 'to_xarray', 'tolist', 'transform', 'transpose', 'truediv', 'truncate', 'tshift', 'tz_convert', 'tz_localize', 'unique', 'unstack', 'update', 'valid', 'value_counts', 'values', 'var', 'view', 'where', 'xs']\n",
      "(Pdb) final_sliced_data[['ops_prob', 'tech_prob', 'product_prob']].max(axis=1).values\n",
      "array([ 0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  1.        ,\n",
      "        1.        ,  0.        ,  0.5       ,  0.5       ,  1.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.5       ,  1.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.5       ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.75      ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
      "        0.66666667,  1.        ,  0.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.66666667,  1.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        1.        ,  1.        ,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.5       ,  0.        ,  1.        ,  0.75      ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.66666667,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
      "        0.5       ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.5       ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.66666667,  1.        ,\n",
      "        0.5       ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.5       ,  1.        ,  0.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.66666667,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.5       ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.5       ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.5       ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.75      ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.5       ,\n",
      "        0.        ,  0.66666667,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.5       ,  0.        ,  1.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.5       ,\n",
      "        0.        ,  1.        ,  0.5       ,  0.5       ,  0.66666667,\n",
      "        1.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.5       ,  1.        ,  1.        ,  0.        ,\n",
      "        0.75      ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.5       ,  0.        ,  0.        ,  1.        ,\n",
      "        0.66666667,  0.66666667,  0.        ,  0.        ,  0.5       ,\n",
      "        0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
      "        1.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.66666667,  0.5       ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.5       ,  1.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  1.        ,  0.5       ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.5       ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.5       ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  1.        ,  0.66666667,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.66666667,  1.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.66666667,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.5       ,\n",
      "        0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        1.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "        1.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.66666667,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.71428571,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.66666667,  0.        ,  0.        ,  0.        ])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) final_sliced_data['ops_prob'] == final_sliced_data[['ops_prob', 'tech_prob', 'product_prob']].max(axis=1)\n",
      "50      True\n",
      "52      True\n",
      "53      True\n",
      "135    False\n",
      "162     True\n",
      "165     True\n",
      "176     True\n",
      "183     True\n",
      "13      True\n",
      "16      True\n",
      "17     False\n",
      "20     False\n",
      "28      True\n",
      "35      True\n",
      "92      True\n",
      "4       True\n",
      "7       True\n",
      "15     False\n",
      "16     False\n",
      "17     False\n",
      "24      True\n",
      "28     False\n",
      "34     False\n",
      "64      True\n",
      "91     False\n",
      "2      False\n",
      "38      True\n",
      "43     False\n",
      "47      True\n",
      "56     False\n",
      "       ...  \n",
      "119     True\n",
      "120     True\n",
      "121     True\n",
      "122     True\n",
      "124     True\n",
      "126     True\n",
      "127    False\n",
      "129     True\n",
      "130     True\n",
      "131     True\n",
      "0       True\n",
      "3       True\n",
      "4       True\n",
      "5       True\n",
      "6       True\n",
      "10      True\n",
      "11      True\n",
      "17      True\n",
      "19      True\n",
      "28      True\n",
      "37      True\n",
      "49      True\n",
      "55      True\n",
      "58      True\n",
      "59      True\n",
      "60      True\n",
      "63      True\n",
      "66      True\n",
      "68      True\n",
      "69      True\n",
      "Length: 1000, dtype: bool\n",
      "(Pdb) (( final_sliced_data['ops_prob'] == final_sliced_data[['ops_prob', 'tech_prob', 'product_prob']].max(axis=1) ) and final_sliced_data[\"Positive\"] == True).astype(int).values\n",
      "*** ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "(Pdb) final_sliced_data['ops_prob'] == final_sliced_data[['ops_prob', 'tech_prob', 'product_prob']].max(axis=1)\n",
      "50      True\n",
      "52      True\n",
      "53      True\n",
      "135    False\n",
      "162     True\n",
      "165     True\n",
      "176     True\n",
      "183     True\n",
      "13      True\n",
      "16      True\n",
      "17     False\n",
      "20     False\n",
      "28      True\n",
      "35      True\n",
      "92      True\n",
      "4       True\n",
      "7       True\n",
      "15     False\n",
      "16     False\n",
      "17     False\n",
      "24      True\n",
      "28     False\n",
      "34     False\n",
      "64      True\n",
      "91     False\n",
      "2      False\n",
      "38      True\n",
      "43     False\n",
      "47      True\n",
      "56     False\n",
      "       ...  \n",
      "119     True\n",
      "120     True\n",
      "121     True\n",
      "122     True\n",
      "124     True\n",
      "126     True\n",
      "127    False\n",
      "129     True\n",
      "130     True\n",
      "131     True\n",
      "0       True\n",
      "3       True\n",
      "4       True\n",
      "5       True\n",
      "6       True\n",
      "10      True\n",
      "11      True\n",
      "17      True\n",
      "19      True\n",
      "28      True\n",
      "37      True\n",
      "49      True\n",
      "55      True\n",
      "58      True\n",
      "59      True\n",
      "60      True\n",
      "63      True\n",
      "66      True\n",
      "68      True\n",
      "69      True\n",
      "Length: 1000, dtype: bool\n",
      "(Pdb) final_sliced_data['ops_prob'] == final_sliced_data[['ops_prob', 'tech_prob', 'product_prob']].max(axis=1) & final_sliced_data[\"Positive\"] == True\n",
      "*** TypeError: unsupported operand type(s) for &: 'float' and 'bool'\n",
      "(Pdb) final_sliced_data[\"Positive\"] == True\n",
      "50     False\n",
      "52     False\n",
      "53     False\n",
      "135    False\n",
      "162    False\n",
      "165    False\n",
      "176    False\n",
      "183    False\n",
      "13     False\n",
      "16     False\n",
      "17     False\n",
      "20     False\n",
      "28     False\n",
      "35     False\n",
      "92     False\n",
      "4      False\n",
      "7      False\n",
      "15     False\n",
      "16     False\n",
      "17     False\n",
      "24     False\n",
      "28     False\n",
      "34     False\n",
      "64     False\n",
      "91     False\n",
      "2      False\n",
      "38     False\n",
      "43     False\n",
      "47     False\n",
      "56     False\n",
      "       ...  \n",
      "119     True\n",
      "120     True\n",
      "121     True\n",
      "122     True\n",
      "124     True\n",
      "126     True\n",
      "127     True\n",
      "129     True\n",
      "130     True\n",
      "131     True\n",
      "0       True\n",
      "3       True\n",
      "4       True\n",
      "5       True\n",
      "6       True\n",
      "10      True\n",
      "11      True\n",
      "17      True\n",
      "19      True\n",
      "28      True\n",
      "37      True\n",
      "49      True\n",
      "55      True\n",
      "58      True\n",
      "59      True\n",
      "60      True\n",
      "63      True\n",
      "66      True\n",
      "68      True\n",
      "69      True\n",
      "Name: Positive, Length: 1000, dtype: bool\n",
      "(Pdb) (( final_sliced_data['ops_prob'] == final_sliced_data[['ops_prob', 'tech_prob', 'product_prob']].max(axis=1) ) & final_sliced_data[\"Positive\"] == True)\n",
      "50     False\n",
      "52     False\n",
      "53     False\n",
      "135    False\n",
      "162    False\n",
      "165    False\n",
      "176    False\n",
      "183    False\n",
      "13     False\n",
      "16     False\n",
      "17     False\n",
      "20     False\n",
      "28     False\n",
      "35     False\n",
      "92     False\n",
      "4      False\n",
      "7      False\n",
      "15     False\n",
      "16     False\n",
      "17     False\n",
      "24     False\n",
      "28     False\n",
      "34     False\n",
      "64     False\n",
      "91     False\n",
      "2      False\n",
      "38     False\n",
      "43     False\n",
      "47     False\n",
      "56     False\n",
      "       ...  \n",
      "119     True\n",
      "120     True\n",
      "121     True\n",
      "122     True\n",
      "124     True\n",
      "126     True\n",
      "127    False\n",
      "129     True\n",
      "130     True\n",
      "131     True\n",
      "0       True\n",
      "3       True\n",
      "4       True\n",
      "5       True\n",
      "6       True\n",
      "10      True\n",
      "11      True\n",
      "17      True\n",
      "19      True\n",
      "28      True\n",
      "37      True\n",
      "49      True\n",
      "55      True\n",
      "58      True\n",
      "59      True\n",
      "60      True\n",
      "63      True\n",
      "66      True\n",
      "68      True\n",
      "69      True\n",
      "Length: 1000, dtype: bool\n",
      "(Pdb) c\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d3c877227db0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;31m#bucket_probabilities =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mfinal_sliced_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ops_positive'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfinal_sliced_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ops_prob'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfinal_sliced_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ops_prob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tech_prob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'product_prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfinal_sliced_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Positive\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;31m# final_sliced_data['product_positive'] = (( final_sliced_data['product_prob'] == max(final_sliced_data['ops_prob'], final_sliced_data['product_prob'], final_sliced_data['tech_prob'])) and final_sliced_data[\"Positive\"] == True )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m# final_sliced_data['tech_positive'] = (( final_sliced_data['tech_prob'] == max(final_sliced_data['ops_prob'], final_sliced_data['product_prob'], final_sliced_data['tech_prob'])) and final_sliced_data[\"Positive\"] == True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work/sentimental_analysis/sentimental/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m   1120\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# bring the data with probability tech + , tech - , ops + , ops - , product + , product -\n",
    "import re\n",
    "tech_list = [\"order\", \"placed\", \"tech\", \"issue\", \"coupon\", \"item\", \"order placed\", \"coupon issue\", \"tech issue\", \"App crash\", \"web crash\", \"ios\", \n",
    "            \"android\", \"signup issue\", \"signin issue\", \"order placed\", \"order confirmation\", \"online payment\", \"hang\", \"too slow\"\n",
    "            , \"cart\", \"image not matching\"]\n",
    "ops_list = [\"delivery\", \"measurement\", \"pickup\", \"refund\",  \"fitting\", \"trial\", \"pickup\", \"refund\", \"deposit\", \"on-time\", \"delay\", \"address updation\", \"return\", \"cancellation\", \"exchange\",\n",
    "\"payment issues\"]\n",
    "product_list = [\"content\", \"available\", \"error\", \"loading\", \"website not loading\", \"site not loading\", \"content not available\", \"cloth tear\", \"defective product\", \"discount codes\"]\n",
    "\n",
    "def calculate_token_probability(item):\n",
    "    tech = 0; ops = 0; product = 0\n",
    "    tokens = item['Review Text'].split(' ')\n",
    "#     for element in tokens:\n",
    "#         #import pdb;pdb.set_trace()\n",
    "#         try:\n",
    "#             tech_match = re.findall(element.lower(), tech_str)\n",
    "#         except Exception:\n",
    "#             tech_match = None\n",
    "            \n",
    "#         try:\n",
    "#             ops_match = re.findall(element.lower(), ops_str)\n",
    "#         except Exception:\n",
    "#             ops_match = None\n",
    "            \n",
    "#         try:\n",
    "#             product_match = re.findall(element.lower(), product_str)\n",
    "#         except Exception:\n",
    "#             product_match = None\n",
    "#         if tech_match:\n",
    "#             tech += 1\n",
    "#         elif ops_match:\n",
    "#             ops += 1\n",
    "#         elif product_match:\n",
    "#             product += 1\n",
    "    tech = [1 for tech_i in tech_list if tech_i.lower() in item['Review Text']]\n",
    "    ops = [1 for ops_i in ops_list if ops_i.lower() in item['Review Text']]\n",
    "    product = [1 for product_i in product_list if product_i.lower() in item['Review Text']]\n",
    "    \n",
    "\n",
    "#     for tech_i in tech_list:\n",
    "#         try:\n",
    "#             tech_match = re.findall(tech_i.lower(), item['Review Text'])\n",
    "#         except Exception:\n",
    "#             tech_match = None\n",
    "            \n",
    "#         if tech_match:\n",
    "#              tech += 1\n",
    "    \n",
    "#     for ops_i in ops_list:\n",
    "#         try:\n",
    "#             ops_match = re.findall(ops_i.lower(), item['Review Text'])\n",
    "#         except Exception:\n",
    "#             ops_match = None\n",
    "            \n",
    "#         if ops_match:\n",
    "#              ops += 1\n",
    "    \n",
    "#     for product_i in product_list:\n",
    "#         try:\n",
    "#             product_match = re.findall(product_i.lower(), item['Review Text'])\n",
    "#         except Exception:\n",
    "#             product_match = None\n",
    "            \n",
    "#         if product_match:\n",
    "#              product += 1\n",
    "            \n",
    "    tech_sum = sum(tech)\n",
    "    ops_sum = sum(ops)\n",
    "    product_sum = sum(product)\n",
    "    \n",
    "    sum_all = tech_sum + ops_sum + product_sum\n",
    "    try:\n",
    "        return pd.Series({'tech_prob': tech_sum/sum_all, 'ops_prob': ops_sum/sum_all, 'product_prob': product_sum/sum_all})\n",
    "    except Exception: \n",
    "        return pd.Series({'tech_prob': 0, 'ops_prob': 0, 'product_prob': 0})\n",
    "    \n",
    "    \n",
    "# def cal(item):\n",
    "#     print(item['Review Text'])\n",
    "#     return pd.Series({'hello': item}, )\n",
    "    \n",
    "probability = sliced_data.apply(calculate_token_probability, axis=1)\n",
    "\n",
    "final_sliced_data = pd.concat([ sliced_data , probability], axis=1)\n",
    "\n",
    "# tech_prob, ops_prob, product_prob = calculate_token_probability(item)\n",
    "# sliced_data[\"tech_positive\"] = sliced_data[\"Review Test\"] in tech\n",
    "# sliced_data[\"tech_negative\"] = sliced_data[\"Review Test\"] not in tech\n",
    "# sliced_data[\"ops_positive\"] = sliced_data[\"Review Test\"] in ops\n",
    "# sliced_data[\"ops_negative\"] = sliced_data[\"Review Test\"] not in ops\n",
    "# sliced_data[\"product_positive\"] = \n",
    "# sliced_data[\"product_negative\"] = \n",
    "#bucket_probabilities = \n",
    "#import pdb;pdb.set_trace()\n",
    "final_sliced_data['ops_positive'] = (( final_sliced_data['ops_prob'] == final_sliced_data[['ops_prob', 'tech_prob', 'product_prob']].max(axis=1) ) & final_sliced_data[\"Positive\"] == True) #.astype(int).values\n",
    "final_sliced_data['product_positive'] = (( final_sliced_data['product_prob'] == final_sliced_data[['ops_prob', 'tech_prob', 'product_prob']].max(axis=1) ) and final_sliced_data[\"Positive\"] == True )\n",
    "final_sliced_data['tech_positive'] = (( final_sliced_data['tech_prob'] == final_sliced_data[['ops_prob', 'tech_prob', 'product_prob']].max(axis=1)  ) and final_sliced_data[\"Positive\"] == True)\n",
    "final_sliced_data['ops_negative'] = (( final_sliced_data['ops_prob'] == final_sliced_data[['ops_prob', 'tech_prob', 'product_prob']].max(axis=1) ) and final_sliced_data[\"Negative\"] == True)\n",
    "final_sliced_data['product_negative'] = (( final_sliced_data['product_prob'] == final_sliced_data[['ops_prob', 'tech_prob', 'product_prob']].max(axis=1) ) and final_sliced_data[\"Negative\"] == True)\n",
    "final_sliced_data['tech_negative'] = (( final_sliced_data['tech_prob'] == final_sliced_data[['ops_prob', 'tech_prob', 'product_prob']].max(axis=1) ) and final_sliced_data[\"Negative\"] == True)\n",
    "final_sliced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50           What's the access code???I am stuck there!!\n",
       "52                                  Stuck in access code\n",
       "53     Quickly send or give an invite code. Email id ...\n",
       "135    I'm glad this thing is now available in India ...\n",
       "162                     how to log in??? access code????\n",
       "Name: Review Text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_data['Review Text'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Star Rating</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Named Entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>What's the access code???I am stuck there!!</td>\n",
       "      <td>Great!!</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[(What, WP), ('s, VBZ), (the, DT), (access, NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Stuck in access code</td>\n",
       "      <td>Access code</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[[(Stuck, NNP)], (in, IN), (access, NN), (code...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Quickly send or give an invite code. Email id ...</td>\n",
       "      <td>NEED AN iNVITE</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[[(Quickly, JJ)], (send, NN), (or, CC), (give,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>I'm glad this thing is now available in India ...</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[(I, PRP), ('m, VBP), (glad, JJ), (this, DT), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>how to log in??? access code????</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[(how, WRB), (to, TO), (log, VB), (in, IN), (?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Review Text    Review Title  \\\n",
       "50         What's the access code???I am stuck there!!         Great!!   \n",
       "52                                Stuck in access code     Access code   \n",
       "53   Quickly send or give an invite code. Email id ...  NEED AN iNVITE   \n",
       "135  I'm glad this thing is now available in India ...                   \n",
       "162                   how to log in??? access code????                   \n",
       "\n",
       "     Star Rating  Positive  Negative  \\\n",
       "50             3     False      True   \n",
       "52             2     False      True   \n",
       "53             3     False      True   \n",
       "135            3     False      True   \n",
       "162            3     False      True   \n",
       "\n",
       "                                        Named Entities  \n",
       "50   [(What, WP), ('s, VBZ), (the, DT), (access, NN...  \n",
       "52   [[(Stuck, NNP)], (in, IN), (access, NN), (code...  \n",
       "53   [[(Quickly, JJ)], (send, NN), (or, CC), (give,...  \n",
       "135  [(I, PRP), ('m, VBP), (glad, JJ), (this, DT), ...  \n",
       "162  [(how, WRB), (to, TO), (log, VB), (in, IN), (?...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate csv file\n",
    "sliced_data.to_csv(\"review_text_data.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_data.loc[sliced_data['Negative'] == True].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_data.loc[sliced_data['Positive'] == True].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Star Rating</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Named Entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Can't even apply discount codes.</td>\n",
       "      <td>None of the tabs seem to be working.</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[(Ca, NNP), (n't, RB), (even, RB), (apply, VB)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Review Text                          Review Title  \\\n",
       "68  Can't even apply discount codes.  None of the tabs seem to be working.   \n",
       "\n",
       "    Star Rating  Positive  Negative  \\\n",
       "68            2     False      True   \n",
       "\n",
       "                                       Named Entities  \n",
       "68  [(Ca, NNP), (n't, RB), (even, RB), (apply, VB)...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_data.loc[sliced_data[\"Review Text\"] == \"Can't even apply discount codes.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_data.to_csv('pos_neg_score.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[[ 238.  262.]\n",
      " [  70.  430.]] 0.668 [[ 400.  100.]\n",
      " [ 336.  164.]] 0.564 [[ 251.  249.]\n",
      " [  74.  426.]] 0.677\n",
      "[[ 238.  262.]\n",
      " [  70.  430.]] 668 [[ 400.  100.]\n",
      " [ 336.  164.]] 564 [[ 251.  249.]\n",
      " [  74.  426.]] 677\n",
      "4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0c7c043897c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;31m#print(review_text.reset_index(drop=True))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m#print(review_text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m'Review Text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreview_text\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_Y\u001b[0m \u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work/sentimental_analysis/sentimental/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    328\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    329\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work/sentimental_analysis/sentimental/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work/sentimental_analysis/sentimental/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6130\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6131\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6132\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work/sentimental_analysis/sentimental/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   6176\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6178\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "#Stratified 10-cross fold validation with SVM and Multinomial NB \n",
    "#labels = np.zeros(1000);\n",
    "labels = (sliced_data[\"Positive\"] == True).astype(int).values;\n",
    "\n",
    "#import pdb;pdb.set_trace()  \n",
    "kf = StratifiedKFold(n_splits=4)\n",
    "\n",
    "totalsvm = 0           # Accuracy measure on 1000 files\n",
    "totalNB = 0\n",
    "totalMLP = 0\n",
    "totalMatSvm = np.zeros((2,2));  # Confusion matrix on 1000 files\n",
    "totalMatNB = np.zeros((2,2));\n",
    "totalMatMLP = np.zeros((2,2));\n",
    "\n",
    "# tr, te = kf.split(sliced_data['Review Text'], labels)\n",
    "# td = []\n",
    "# for i in train_index:\n",
    "#     td.append(sliced_data['Review Text'][i])\n",
    "#import pdb;pdb.set_trace()\n",
    "review_text = sliced_data['Review Text'].tolist()\n",
    "\n",
    "# break words\n",
    "review_words = []\n",
    "\n",
    "# for item in review_text:\n",
    "#     review_words += item.split(\" \")\n",
    "counter = 0\n",
    "for train_index, test_index in kf.split(review_text, labels):\n",
    "    #import pdb;pdb.set_trace()\n",
    "    #print(train_index.__len__(), test_index.__len__())\n",
    "    X_train = [review_text[i] for i in train_index]\n",
    "    X_test = [review_text[i] for i in test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    vectorizer = TfidfVectorizer(min_df=1, max_df = 2, sublinear_tf=True, use_idf=True,stop_words='english')\n",
    "    train_corpus_tf_idf = vectorizer.fit_transform(X_train) \n",
    "    test_corpus_tf_idf = vectorizer.transform(X_test)\n",
    "\n",
    "    \n",
    "    model1 = LinearSVC()\n",
    "    model2 = MultinomialNB()\n",
    "    model3 = MLPClassifier()\n",
    "    # Max entropy\n",
    "    model1.fit(train_corpus_tf_idf,y_train)\n",
    "    model2.fit(train_corpus_tf_idf,y_train)\n",
    "    model3.fit(train_corpus_tf_idf,y_train)\n",
    "    result1 = model1.predict(test_corpus_tf_idf)\n",
    "    result2 = model2.predict(test_corpus_tf_idf)\n",
    "    result3 = model3.predict(test_corpus_tf_idf)\n",
    "    \n",
    "    totalMatSvm = totalMatSvm + confusion_matrix(y_test, result1)\n",
    "    totalMatNB = totalMatNB + confusion_matrix(y_test, result2)\n",
    "    totalMatMLP = totalMatMLP + confusion_matrix(y_test, result3)\n",
    "    totalsvm = totalsvm + sum(y_test==result1)\n",
    "    totalNB = totalNB + sum(y_test==result2)\n",
    "    totalMLP = totalMLP + sum(y_test==result3)\n",
    "    counter += 1\n",
    "    test_corpus = vectorizer.transform([\"I really liked the service.\"])\n",
    "    result_test = model3.predict(test_corpus)\n",
    "    print(result_test)\n",
    "    prev = sliced_data.iloc[test_index, :]\n",
    "    test = pd.DataFrame( { 'Review Text': X_test , 'Sentiment': result3, \n",
    "                          'Positive': prev[\"Positive\"], \n",
    "                          'Negative': prev[\"Negative\"],\n",
    "                         'Star Rating': prev[\"Star Rating\"]} )\n",
    "    test.to_csv( 'sentiment_prediction'+str(counter)+'.csv' , index = False )\n",
    "    \n",
    "    \n",
    "print(totalMatSvm, totalsvm/1000.0, totalMatNB, totalNB/1000.0, totalMatMLP, totalMLP/1000.0)\n",
    "\n",
    "\n",
    "print(totalMatSvm, totalsvm, totalMatNB, totalNB, totalMatMLP, totalMLP)\n",
    "#test.to_csv( 'sentiment_prediction.csv' , index = False )\n",
    "\n",
    "#print(train_corpus_tf_idf, test_corpus_tf_idf)\n",
    "\n",
    "test_Y = model2.predict( test_corpus_tf_idf )\n",
    "#print(test_Y)\n",
    "print(counter)\n",
    "#print(X_test)\n",
    "\n",
    "#print(results_list)\n",
    "#print(review_text.reset_index(drop=True))\n",
    "#print(review_text)\n",
    "# test = pd.DataFrame( { 'Review Text': review_text , 'Sentiment': test_Y } )\n",
    "# test.shape\n",
    "# test.head()\n",
    "#test.to_csv( 'sentiment_prediction.csv' , index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Tree('S', [('Where', 'WRB'), ('is', 'VBZ'), ('my', 'PRP$'), ('order', 'NN'), (',', ','), ('concerned', 'VBN'), ('about', 'IN'), ('the', 'DT'), ('delivery', 'NN'), ('of', 'IN'), ('my', 'PRP$'), ('order', 'NN')])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sentence = \"Where is my order, concerned about the delivery of my order\"\n",
    " \n",
    "chunk = ne_chunk(pos_tag(word_tokenize(sentence)))\n",
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mark', 'NNP')]\n",
      "[('John', 'NNP')]\n",
      "[('Google', 'NNP')]\n",
      "[('Awesome', 'NNP')]\n",
      "[('Flyrobe', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "tech = [\"order placed\", \"tech\", \"issue\", \"coupon\", \"item\"]\n",
    "ops = [\"delivery\", \"measurement\", \"pickup\", \"refund\"]\n",
    "product = [\"site content\", \"content not available\", \"error at site\", \"site not loading\"]\n",
    "\n",
    "def nltk_entities(review_texts=None):\n",
    "    \"\"\"\n",
    "    Extract entities using the NLTK named entity chunker.\n",
    "    \"\"\"\n",
    "    results = defaultdict(lambda: defaultdict(list))\n",
    "    #fileids = fileids or corpus.fileids()\n",
    "\n",
    "    for count, review in enumerate(review_texts):\n",
    "        #print(review)\n",
    "        #import pdb;pdb.set_trace()\n",
    "#         if section is not None:\n",
    "#             text = nltk.pos_tag(nltk.word_tokenize(list(sectpull([fileid],section=section))[0][1]))\n",
    "#         else:\n",
    "#             text = nltk.pos_tag(corpus.words(fileid))\n",
    "#         text =  pos_tag(review)\n",
    "#         print(text)\n",
    "        for entity in ne_chunk(pos_tag(word_tokenize(review))):\n",
    "            \n",
    "            if isinstance(entity, tree.Tree):\n",
    "                etext = \" \".join([word for word, tag in entity.leaves()])\n",
    "                print(entity.leaves())\n",
    "                label = entity.label()\n",
    "            else:\n",
    "                continue\n",
    "            #print(entity)\n",
    "            if label == 'PERSON':\n",
    "                key = 'persons'\n",
    "            elif label == 'ORGANIZATION':\n",
    "                key = 'organizations'\n",
    "            elif label == 'LOCATION':\n",
    "                key = 'locations'\n",
    "            elif label == 'GPE':\n",
    "                key = 'other'\n",
    "            elif label in tech:\n",
    "                key = 'tech'\n",
    "            elif label in ops:\n",
    "                key = 'ops'\n",
    "            elif label in product:\n",
    "                key = 'product'\n",
    "            \n",
    "            else:\n",
    "                key = None\n",
    "                \n",
    "            #print(\"________\",label)\n",
    "            \n",
    "            if key:\n",
    "                results[count][key].append(etext)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "review_text_list = [\"Mark and John are working at Google.\" , \"Awesome collection in Flyrobe\", \"Where is my order, concerned about the delivery of my order\"] \n",
    "nltkents = nltk_entities(review_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.nltk_entities.<locals>.<lambda>>,\n",
       "            {0: defaultdict(list,\n",
       "                         {'organizations': ['Google'],\n",
       "                          'persons': ['Mark', 'John']}),\n",
       "             1: defaultdict(list, {'other': ['Awesome', 'Flyrobe']})})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltkents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
